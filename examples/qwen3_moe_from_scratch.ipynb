{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Course: Training a Custom Tiny Qwen3 MoE LLM from Scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I welcome you to this hands-on course where we build and train a Large Language Model (LLM) entirely from scratch only on Apple Silicon using MLX-LM and my package MLX-LM-LoRA.\n",
    "\n",
    "This is not another ‚Äúfine-tune GPT‚Äù course ‚Äî we‚Äôre creating a custom MoE model architecture, pretraining it on web-scale data, finetuning it using supervised data, and optimizing it with preference learning. All of it runs locally on your Mac.\n",
    "\n",
    "---\n",
    "\n",
    "üì¶ Minimum Requirements\n",
    "\n",
    "To run this notebook locally, you‚Äôll need:\n",
    "- An Apple Silicon Mac (M1 Pro / M2 Max / M3, etc.)\n",
    "- Minimum 32 GB of unified memory (lower is also possible, but you'd have to change parameters to fit, Higher is better)\n",
    "- Python ‚â• 3.12\n",
    "\n",
    "---\n",
    "\n",
    "üìö Course Overview\n",
    "\n",
    "This course covers the entire LLM training stack:\n",
    "1.\tModel Design: Define a Tiny Qwen3 MoE-style model\n",
    "2.\tPretraining: Unsupervised training on `mlx-community/fineweb-200k`\n",
    "3.\tSupervised Finetuning (SFT): Using a subset of `digitalpipelines/wizard_vicuna_70k_uncensored`\n",
    "4.\tPreference Optimization: With `mlx-community/Human-Like-DPO`\n",
    "5.\tEvaluation + Inference: Test generations and evaluation\n",
    "\n",
    "---\n",
    "\n",
    "ü§ñ Model Architecture: Tiny Qwen3 MoE\n",
    "\n",
    "We‚Äôll build a custom minimal MoE version of the new Qwen3. The model uses:\n",
    "- Transformer decoder-only blocks\n",
    "- Sparse Mixture-of-Experts layers\n",
    "- Rotary embeddings (RoPE)\n",
    "\n",
    "We aim to keep it light enough to fully train on-device.\n",
    "\n",
    "---\n",
    "\n",
    "üß™ Pretraining Dataset: mlx-community/fineweb-200k\n",
    "\n",
    "We‚Äôll use a subset of the FineWeb dataset hosted on Hugging Face:\n",
    "mlx-community/fineweb-200k\n",
    "\n",
    "It is:\n",
    "- Cleaned, deduplicated web content\n",
    "- Ideal for unsupervised autoregressive training\n",
    "- Efficiently streamed on Apple Silicon\n",
    "\n",
    "---\n",
    "\n",
    "üßæ Prompt Templates\n",
    "\n",
    "We‚Äôll use a custom prompt template to go with Qwen3.\n",
    "For finetuning, we adopt the following ChatLM-style template:\n",
    "\n",
    "```text\n",
    "<|im_start|>system description\n",
    "This is a conversation between Josie, a helpfull AI assistant and a human user.<|im_end|>\n",
    "<|im_start|>user turn\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant turn, name = 'Josie'\n",
    "{answer}<|im_end|>\n",
    "```\n",
    "\n",
    "This helps align with conversational-tuned models and enables easy preference optimization later.\n",
    "\n",
    "---\n",
    "\n",
    "üß† SFT Dataset: digitalpipelines/wizard_vicuna_70k_uncensored\n",
    "\n",
    "We‚Äôll use the Wizard Vicuna dataset, known for:\n",
    "- Rich instruction-following data\n",
    "- Clean conversational structure\n",
    "- Multi turn conversations\n",
    "- Aligned with assistant-style prompting\n",
    "\n",
    "This stage teaches the model how a conversation looks like.\n",
    "\n",
    "---\n",
    "\n",
    "‚ù§Ô∏è Preference Optimization: mlx-community/Human-Like-DPO\n",
    "\n",
    "To refine the model‚Äôs behavior further, We‚Äôll apply Monolithic Preference Optimization (ORPO) using:\n",
    "\n",
    "mlx-community/Human-Like-DPO\n",
    "\n",
    "This dataset includes:\n",
    "- Ranked preference pairs\n",
    "- Human-like instructions and completions\n",
    "- Fine-grained reward signal for better alignment\n",
    "\n",
    "---\n",
    "\n",
    "üß∞ Tools Used\n",
    "- MLX-LM: Apple-native LLM framework leveraging MLX runtime\n",
    "- MLX-LM-LoRA: My package for full-precision and LoRA training, supporting DPO, ORPO, GRPO and more\n",
    "- Hugging Face Datasets + Transformers for data loading and formatting\n",
    "\n",
    "---\n",
    "\n",
    "üèÅ By The End Of This Course‚Ä¶\n",
    "\n",
    "You‚Äôll have:\n",
    "- Designed and built a custom Qwen3 MoE model\n",
    "- Pretrained it on web-scale text\n",
    "- Supervised-finetuned it on instruction data\n",
    "- Aligned it using preference optimization\n",
    "- Deployed and evaluated it entirely on your Mac\n",
    "\n",
    "Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Installation: Set Up the Environment\n",
    "\n",
    "Before we begin training, let‚Äôs install all necessary dependencies.\n",
    "\n",
    "We‚Äôll use:\n",
    "- `mlx-lm-lora` ‚Äì includes mlx-lm, datasets\n",
    "- `huggingface_hub` ‚Äì for uploading our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlx-lm-lora huggingface_hub wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Imports and Setup\n",
    "\n",
    "Before building and training our Qwen3-style MoE model, we import everything needed:\n",
    "- Core Python utilities (os, Path, dataclass)\n",
    "- MLX-LM-LORA tools for defining models and saving configs\n",
    "- HF token/tokenizer setup\n",
    "- Model class and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm_lora.trainer.datasets import CacheDataset, ORPODataset, TextDataset\n",
    "from mlx_lm_lora.trainer.orpo_trainer import ORPOTrainingArgs, train_orpo\n",
    "from mlx_lm_lora.trainer.sft_trainer import SFTTrainingArgs, train_sft\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import create_repo, HfApi\n",
    "\n",
    "from mlx_lm.tuner.utils import linear_to_lora_layers, print_trainable_parameters, get_total_parameters\n",
    "from mlx_lm.utils import load, load_model, load_tokenizer, save_config, save_model\n",
    "from mlx_lm.models.qwen3_moe import Model, BaseModelArgs\n",
    "from mlx_lm.tuner.callbacks import TrainingCallback\n",
    "from mlx_lm import generate\n",
    "\n",
    "import mlx.optimizers as optim\n",
    "from mlx_optimizers import Muon\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "import math\n",
    "import os\n",
    "\n",
    "def calculate_iters(train_set, batch_size, epochs) -> int:\n",
    "    num_samples = len(train_set)\n",
    "    batches_per_epoch = math.ceil(num_samples / batch_size)\n",
    "    iters = epochs * batches_per_epoch\n",
    "    print(f\"[INFO] Calculated {iters} iterations from {epochs} epochs (dataset size: {num_samples}, batch size: {batch_size})\")\n",
    "    return iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå Setup: Define HF Token and Model Metadata\n",
    "\n",
    "Before training or uploading, we set up:\n",
    "- Your Hugging Face token for authentication\n",
    "- The model name (used for saving)\n",
    "- The user or organization name\n",
    "- The local path where everything will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"\" # <-- Add you HF Token here\n",
    "\n",
    "new_model_name = \"qwen3_tiny_moe\"\n",
    "user_name = \"mlx-community\"\n",
    "author = \"G√∂kdeniz G√ºlmez\"\n",
    "\n",
    "folder = \"/Users/gokdenizgulmez/Desktop/mlx-lm-lora/examples/\"\n",
    "\n",
    "pretraining_dataset_name = \"mlx-community/fineweb-200k\"\n",
    "pretraining_dataset_samples = 2000\n",
    "\n",
    "finetuning_dataset_name = \"digitalpipelines/wizard_vicuna_70k_uncensored\"\n",
    "finetuning_dataset_samples = 1000\n",
    "\n",
    "preference_dataset_name = \"mlx-community/Human-Like-DPO\"\n",
    "preference_dataset_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÅ Prepare Target Directory for Model & Tokenizer\n",
    "\n",
    "We define the full target path for saving the model and tokenizer.\n",
    "\n",
    "If it doesn‚Äôt already exist, we:\n",
    "- Clone the custom tokenizer repo from Hugging Face\n",
    "- Place it inside the model folder\n",
    "\n",
    "Otherwise, we skip cloning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = os.path.join(folder, new_model_name)\n",
    "if not os.path.exists(target_dir):\n",
    "    !git clone https://huggingface.co/Goekdeniz-Guelmez/qwen3_tokenizer \"{target_dir}\"\n",
    "else:\n",
    "    print(f\"Tokenizer already exists at: {target_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß± Define Model Configuration\n",
    "\n",
    "We subclass the BaseModelArgs to create a tiny Qwen3 MoE architecture:\n",
    "- Shallow network with only 2 layers\n",
    "- Small hidden size (128) for fast local training\n",
    "- 4 experts, 1 active per token (simple MoE routing)\n",
    "- Tokenizer and embedding sizes that match Qwen3\n",
    "\n",
    "This keeps the model small enough to:\n",
    "- Fit on local Apple Silicon\n",
    "- Still support pretraining and ORPO finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NewModelArgs(BaseModelArgs):\n",
    "    mlp_only_layers: list[int] = field(default_factory=list)  # Default: no MLP-only layers\n",
    "\n",
    "    model_type: str = \"qwen3_moe\"\n",
    "    \n",
    "    hidden_size: int = 128                   # Tiny, but enough for basic functionality\n",
    "    num_hidden_layers: int = 2               # Very shallow\n",
    "    intermediate_size: int = 256             # Typically 2x hidden size\n",
    "    moe_intermediate_size: int = 256         # Same as above, or slightly larger\n",
    "    num_attention_heads: int = 2             # Must divide hidden_size\n",
    "    num_key_value_heads: int = 1             # Often set to 1 for tiny models\n",
    "    head_dim: int = field(init=False)        # Will be computed post-init\n",
    "    num_experts: int = 4                     # Small MoE with minimal experts\n",
    "    num_experts_per_tok: int = 1             # One expert per token\n",
    "    decoder_sparse_step: int = 1             # Typical setting\n",
    "\n",
    "    rms_norm_eps: float = 1e-6               # Standard value\n",
    "    vocab_size: int = 151936                 # Matches Qwen3 tokenizer size\n",
    "    rope_theta: float = 1000.0               # Qwen3 uses 1e3\n",
    "\n",
    "    tie_word_embeddings: bool = True         # Save params, good default\n",
    "    max_position_embeddings: int = 1028      # Common default\n",
    "    norm_topk_prob: bool = True              # MoE-specific regularization trick\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.head_dim = self.hidden_size // self.num_attention_heads  # Auto-calculated\n",
    "\n",
    "args = NewModelArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Initialize the Model\n",
    "\n",
    "We instantiate the model using the configuration from the previous cell. This builds the full architecture in memory, ready for pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = Model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Inspect the Model\n",
    "\n",
    "We print:\n",
    "- The full architecture and parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(untrained_model)\n",
    "print(f\"{int(get_total_parameters(untrained_model) / 1e6):.3f}M total parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Save Model & Config to Disk\n",
    "\n",
    "We store:\n",
    "- The full args configuration as config.json\n",
    "- The initial (untrained) model weights using save_model(...)\n",
    "\n",
    "This gives us a checkpointable starting point for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_config(vars(args), f\"{target_dir}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(Path(target_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Pretraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.join(target_dir, \"pretrained\")\n",
    "pretrain_folder = Path(pretrain_path)\n",
    "pretrain_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_opt = Muon(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_dataset = load_dataset(pretraining_dataset_name)[\"train\"]\n",
    "\n",
    "if pretraining_dataset_samples is not None:\n",
    "    pretraining_dataset = pretraining_dataset.select(range(pretraining_dataset_samples))\n",
    "\n",
    "pretraining_train_dataset, pretraining_valid_dataset = pretraining_dataset.train_test_split(test_size=0.01, seed=42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_train_set = TextDataset(pretraining_train_dataset, tokenizer, text_key='text')\n",
    "pretraining_valid_set = TextDataset(pretraining_valid_dataset, tokenizer, text_key='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 1\n",
    "\n",
    "train_sft(\n",
    "    model=untrained_model,\n",
    "    args=SFTTrainingArgs(\n",
    "        batch_size=batch_size,\n",
    "        iters=calculate_iters(train_set=pretraining_train_set, batch_size=batch_size, epochs=epochs),\n",
    "        val_batches=1,\n",
    "        steps_per_report=20,\n",
    "        steps_per_eval=50,\n",
    "        steps_per_save=-1,\n",
    "        max_seq_length=untrained_model.args.max_position_embeddings,\n",
    "        grad_checkpoint=True,\n",
    "    ),\n",
    "    optimizer=pretraining_opt,\n",
    "    train_dataset=CacheDataset(pretraining_train_set),\n",
    "    val_dataset=CacheDataset(pretraining_valid_set),\n",
    "    training_callback=TrainingCallback()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_new_model_name = f\"pretrained_{new_model_name}\"\n",
    "\n",
    "readme_file = f\"\"\"---\n",
    "tags:\n",
    "- mlx\n",
    "- text-generation\n",
    "pipeline_tag: text-generation\n",
    "---\n",
    "\n",
    "# Fully Pretrained Model: `{user_name}/{pretrained_new_model_name}`\n",
    "\n",
    "This model was **pretrained from scratch** using the [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) training package on Apple Silicon via MLX.  \n",
    "It is part of the **\"Creating LLMs from Scratch\"** notebook series by G√∂kdeniz G√ºlmez.\n",
    "\n",
    "The model was trained on a subset of **{pretraining_dataset_name}**, using **{pretraining_dataset_samples}** samples.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Model Details\n",
    "\n",
    "| Field                | Value                                   |\n",
    "|---------------------|-----------------------------------------|\n",
    "| **Model name**       | `{pretrained_new_model_name}`                     |\n",
    "| **Pretraining type** | Full from scratch                      |\n",
    "| **Training package** | [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) |\n",
    "| **Model type**       | {untrained_model.args.model_type}      |\n",
    "| **Author**           | {author}                               |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Usage Example (Python)\n",
    "\n",
    "```python\n",
    "from mlx_lm.utils import load_model, load_tokenizer\n",
    "from mlx_lm import generate\n",
    "\n",
    "tokenizer = load_tokenizer(\"Goekdeniz-Guelmez/qwen3_tokenizer\")\n",
    "model = load_model(\"{user_name}/{pretrained_new_model_name}\")\n",
    "\n",
    "generate(model, tokenizer, \"What is the meaning of life?\")\n",
    "\"\"\"\n",
    "\n",
    "new_readme_path = f\"{pretrain_path}/README.md\"\n",
    "with open(new_readme_path, \"w\") as new_readme_file:\n",
    "    new_readme_file.write(readme_file)\n",
    "\n",
    "save_model(pretrain_path, untrained_model)\n",
    "save_config(vars(args), f\"{pretrain_path}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi(token=hf_token)\n",
    "create_repo(\n",
    "  repo_id = f\"{user_name}/{pretrained_new_model_name}\",\n",
    "  repo_type=\"model\",\n",
    "  exist_ok=True,\n",
    "  token=hf_token,\n",
    "  private=True\n",
    ")\n",
    "api.upload_folder(\n",
    "  folder_path=new_model_name,\n",
    "  repo_id=f\"{user_name}/{new_model_name}\",\n",
    "  token=hf_token,\n",
    "  commit_message=\"Initial Commit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete model from RAM\n",
    "\n",
    "You might also restart the Notebook but be sure you have the pretrained model path before you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del untrained_model, args, pretrain_folder, pretraining_opt, pretraining_dataset, pretraining_train_dataset, pretraining_valid_dataset, pretraining_train_set, pretraining_valid_set, readme_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start LoRA SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = load_model(pretrain_path)\n",
    "\n",
    "max_seq_length = 512\n",
    "num_lora_layers = 12\n",
    "lora_parameters = {\"rank\": 8, \"dropout\": 0.0, \"scale\": 10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_path = os.path.join(target_dir, \"finetuned\")\n",
    "finetune_folder = Path(finetune_path)\n",
    "finetune_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.freeze()\n",
    "\n",
    "linear_to_lora_layers(\n",
    "    model=pretrained_model,\n",
    "    num_layers=num_lora_layers,\n",
    "    config=lora_parameters,\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "print_trainable_parameters(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_args = {\n",
    "    \"lora_parameters\": lora_parameters,\n",
    "    \"num_layers\": num_lora_layers,\n",
    "}\n",
    "\n",
    "finetune_adapter_path = Path(os.path.join(finetune_path, \"adapters\"))\n",
    "finetune_adapter_path.mkdir(parents=True, exist_ok=True)\n",
    "save_config(vars(lora_args), finetune_adapter_path / \"adapter_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"This is a conversation between Josie, a helpfull AI assistant and a human user.\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "full_prompt_format = \"\"\"<|im_start|>system description\n",
    "{}<|im_end|>\n",
    "<|im_start|>user turn\n",
    "{}<|im_end|>\n",
    "<|im_start|>assistant turn, name = 'Josie'\n",
    "{}\"\"\"\n",
    "\n",
    "system_turn = \"\"\"<|im_start|>system description\n",
    "{}\"\"\"\n",
    "\n",
    "user_turn = \"\"\"\n",
    "<|im_start|>user turn\n",
    "{}\"\"\"\n",
    "\n",
    "assistant_turn = \"\"\"\n",
    "<|im_start|>assistant turn, name = 'Josie'\n",
    "{}\"\"\"\n",
    "\n",
    "def format_prompts_func(sample):\n",
    "    this_conversation = sample[\"conversations\"]\n",
    "\n",
    "    if isinstance(this_conversation, list):\n",
    "        conversation = system_turn.format(system_prompt + EOS_TOKEN)\n",
    "        for turn in this_conversation:\n",
    "            if turn[\"from\"] == \"human\":\n",
    "                conversation += user_turn.format(turn['value'] + EOS_TOKEN)\n",
    "            elif turn[\"from\"] == \"gpt\":\n",
    "                conversation += assistant_turn.format(turn['value'] + EOS_TOKEN)\n",
    "\n",
    "    sample[\"text\"] = conversation\n",
    "    return sample\n",
    "\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_name)[\"train\"]\n",
    "\n",
    "if finetuning_dataset_samples is not None:\n",
    "    finetuning_dataset = finetuning_dataset.select(range(finetuning_dataset_samples))\n",
    "\n",
    "finetuning_dataset = finetuning_dataset.map(format_prompts_func,)\n",
    "finetuning_train_dataset, finetuning_valid_dataset = finetuning_dataset.train_test_split(test_size=0.01, seed=42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_train_set = TextDataset(finetuning_train_dataset, tokenizer, text_key='text')\n",
    "finetuning_valid_set = TextDataset(finetuning_valid_dataset, tokenizer, text_key='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_opt = optim.AdamW(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 1\n",
    "\n",
    "train_sft(\n",
    "    model=pretrained_model,\n",
    "    args=SFTTrainingArgs(\n",
    "        batch_size=batch_size,\n",
    "        iters=calculate_iters(train_set=finetuning_train_set, batch_size=batch_size, epochs=epochs),\n",
    "        val_batches=1,\n",
    "        steps_per_report=20,\n",
    "        steps_per_eval=50,\n",
    "        steps_per_save=50,\n",
    "        adapter_file=finetune_adapter_path,\n",
    "        max_seq_length=max_seq_length,\n",
    "        grad_checkpoint=True,\n",
    "    ),\n",
    "    optimizer=finetuning_opt,\n",
    "    train_dataset=CacheDataset(finetuning_train_set),\n",
    "    val_dataset=CacheDataset(finetuning_valid_set),\n",
    "    training_callback=TrainingCallback()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_new_model_name = f\"finetuned_{new_model_name}\"\n",
    "\n",
    "readme_file = f\"\"\"---\n",
    "tags:\n",
    "- mlx\n",
    "- text-generation\n",
    "pipeline_tag: text-generation\n",
    "---\n",
    "\n",
    "# Finetuned Model: `{user_name}/{finetuned_new_model_name}`\n",
    "\n",
    "This model was **finetuned** using the [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) training package on Apple Silicon via MLX.  \n",
    "It builds upon the base model {pretrained_new_model_name} that was previously **pretrained from scratch** and is part of the **\"Creating LLMs from Scratch\"** notebook series by G√∂kdeniz G√ºlmez.\n",
    "\n",
    "The fine-tuning was performed on a subset of **{finetuning_dataset_name}**, using **{finetuning_dataset_samples}** samples.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Model Details\n",
    "\n",
    "| Field                | Value                                   |\n",
    "|---------------------|-----------------------------------------|\n",
    "| **Model name**       | `{finetuned_new_model_name}`                     |\n",
    "| **Finetuning type**  | Supervised fine-tuning (SFT)            |\n",
    "| **Training package** | [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) |\n",
    "| **Base model**       | {untrained_model.args.model_type}       |\n",
    "| **Author**           | {author}                                |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Usage Example (Python)\n",
    "\n",
    "```python\n",
    "from mlx_lm.utils import load_model, load_tokenizer\n",
    "from mlx_lm import generate\n",
    "\n",
    "tokenizer = load_tokenizer(\"Goekdeniz-Guelmez/qwen3_tokenizer\")\n",
    "model = load_model(\"{user_name}/{finetuned_new_model_name}\")\n",
    "\n",
    "generate(model, tokenizer, \"What is the meaning of life?\")\n",
    "\"\"\"\n",
    "\n",
    "new_readme_path = f\"{finetune_path}/README.md\"\n",
    "with open(new_readme_path, \"w\") as new_readme_file:\n",
    "    new_readme_file.write(readme_file)\n",
    "\n",
    "save_model(finetune_path, finetune_path)\n",
    "save_config(vars(args), f\"{finetune_path}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi(token=hf_token)\n",
    "create_repo(\n",
    "  repo_id = f\"{user_name}/{finetuned_new_model_name}\",\n",
    "  repo_type=\"model\",\n",
    "  exist_ok=True,\n",
    "  token=hf_token,\n",
    "  private=True\n",
    ")\n",
    "api.upload_folder(\n",
    "  folder_path=new_model_name,\n",
    "  repo_id=f\"{user_name}/{new_model_name}\",\n",
    "  token=hf_token,\n",
    "  commit_message=\"Initial Commit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pretrained_model, finetune_folder, finetune_adapter_path, finetuning_opt, finetuning_dataset, finetuning_train_dataset, finetuning_valid_dataset, finetuning_train_set, finetuning_valid_set, readme_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Preference Optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = load_model(finetune_path)\n",
    "\n",
    "max_seq_length = finetuned_model.args.max_position_embeddings\n",
    "num_lora_layers = -1\n",
    "lora_parameters = {\"rank\": 8, \"dropout\": 0.0, \"scale\": 10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_path = os.path.join(target_dir, \"preference_optmimzed\")\n",
    "preference_folder = Path(preference_path)\n",
    "preference_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.freeze()\n",
    "\n",
    "linear_to_lora_layers(\n",
    "    model=finetuned_model,\n",
    "    num_layers=num_lora_layers,\n",
    "    config=lora_parameters,\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "print_trainable_parameters(finetuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_args = {\n",
    "    \"lora_parameters\": lora_parameters,\n",
    "    \"num_layers\": num_lora_layers,\n",
    "}\n",
    "\n",
    "finetune_adapter_path = Path(os.path.join(finetune_path, \"adapters\"))\n",
    "finetune_adapter_path.mkdir(parents=True, exist_ok=True)\n",
    "save_config(vars(lora_args), finetune_adapter_path / \"adapter_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"This is a conversation between Josie, a helpfull AI assistant and a human user.\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "full_prompt_format = \"\"\"<|im_start|>system description\n",
    "{}<|im_end|>\n",
    "<|im_start|>user turn\n",
    "{}<|im_end|>\n",
    "<|im_start|>assistant turn, name = 'Josie'\n",
    "{}\"\"\"\n",
    "\n",
    "system_turn = \"\"\"<|im_start|>system description\n",
    "{}\"\"\"\n",
    "\n",
    "user_turn = \"\"\"\n",
    "<|im_start|>user turn\n",
    "{}\"\"\"\n",
    "\n",
    "assistant_turn = \"\"\"\n",
    "<|im_start|>assistant turn, name = 'Josie'\n",
    "{}\"\"\"\n",
    "\n",
    "def format_prompts_func(sample):\n",
    "    prompt = sample[\"prompt\"]\n",
    "    chosen = sample[\"chosen\"]\n",
    "    rejected = sample[\"rejected\"]\n",
    "\n",
    "    chosen_conversation = full_prompt_format.format(system_prompt, prompt, chosen)\n",
    "    rejected_conversation = full_prompt_format.format(system_prompt, prompt, rejected)\n",
    "\n",
    "    sample[\"rejected\"] = rejected_conversation\n",
    "    sample[\"chosen\"] = chosen_conversation\n",
    "    return sample\n",
    "\n",
    "preference_dataset = load_dataset(preference_dataset_name)[\"train\"]\n",
    "\n",
    "if preference_dataset_samples is not None:\n",
    "    preference_dataset = preference_dataset.select(range(preference_dataset_samples))\n",
    "\n",
    "preference_dataset = preference_dataset.map(format_prompts_func,)\n",
    "preference_train_dataset, preference_valid_dataset = preference_dataset.train_test_split(test_size=0.01, seed=42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_train_set = ORPODataset(preference_train_dataset, tokenizer)\n",
    "preference_valid_set = ORPODataset(preference_valid_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_opt = optim.AdamW(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 2\n",
    "\n",
    "train_orpo(\n",
    "    model=finetuned_model,\n",
    "    args=ORPOTrainingArgs(\n",
    "        batch_size=batch_size,\n",
    "        iters=calculate_iters(train_set=preference_train_set, batch_size=batch_size, epochs=epochs),\n",
    "        val_batches=1,\n",
    "        steps_per_report=20,\n",
    "        steps_per_eval=50,\n",
    "        steps_per_save=50,\n",
    "        adapter_file=preference_path,\n",
    "        max_seq_length=max_seq_length,\n",
    "        grad_checkpoint=True,\n",
    "        beta=0.1,\n",
    "        reward_scaling=0.6\n",
    "    ),\n",
    "    optimizer=preference_opt,\n",
    "    train_dataset=CacheDataset(preference_train_set),\n",
    "    val_dataset=CacheDataset(preference_valid_set),\n",
    "    training_callback=TrainingCallback()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_new_model_name = f\"preference_optimized_{new_model_name}\"\n",
    "\n",
    "readme_file = f\"\"\"---\n",
    "tags:\n",
    "- mlx\n",
    "- text-generation\n",
    "pipeline_tag: text-generation\n",
    "---\n",
    "\n",
    "# Preference-Optimized Model: `{user_name}/{preference_new_model_name}`\n",
    "\n",
    "This model was optimized via **preference-based alignment** using the [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) training package on Apple Silicon via MLX.  \n",
    "It builds upon a model that was **pretrained from scratch** and then **fine-tuned** with supervised learning, forming part of the **\"Creating LLMs from Scratch\"** notebook series by G√∂kdeniz G√ºlmez.\n",
    "\n",
    "The preference optimization phase used **{preference_dataset_name}** with **{preference_dataset_samples}** ranked prompt pairs to align model outputs with human preferences.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Model Details\n",
    "\n",
    "| Field                    | Value                                          |\n",
    "|-------------------------|------------------------------------------------|\n",
    "| **Model name**           | `{preference_new_model_name}`                           |\n",
    "| **Alignment type**       | Preference Optimization (e.g. DPO/ORPO/GRPO)   |\n",
    "| **Training package**     | [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) |\n",
    "| **Base model**           | {untrained_model.args.model_type}             |\n",
    "| **Author**               | {author}                                      |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Usage Example (Python)\n",
    "\n",
    "```python\n",
    "from mlx_lm.utils import load_model, load_tokenizer\n",
    "from mlx_lm import generate\n",
    "\n",
    "tokenizer = load_tokenizer(\"Goekdeniz-Guelmez/qwen3_tokenizer\")\n",
    "model = load_model(\"{user_name}/{preference_new_model_name}\")\n",
    "\n",
    "generate(model, tokenizer, \"What is the meaning of life?\")\n",
    "\"\"\"\n",
    "\n",
    "new_readme_path = f\"{preference_path}/README.md\"\n",
    "with open(new_readme_path, \"w\") as new_readme_file:\n",
    "    new_readme_file.write(readme_file)\n",
    "\n",
    "save_model(preference_path, finetuned_model)\n",
    "save_config(vars(args), f\"{preference_path}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi(token=hf_token)\n",
    "create_repo(\n",
    "  repo_id = f\"{user_name}/{pretrained_new_model_name}\",\n",
    "  repo_type=\"model\",\n",
    "  exist_ok=True,\n",
    "  token=hf_token,\n",
    "  private=True\n",
    ")\n",
    "api.upload_folder(\n",
    "  folder_path=new_model_name,\n",
    "  repo_id=f\"{user_name}/{new_model_name}\",\n",
    "  token=hf_token,\n",
    "  commit_message=\"Initial Commit\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
