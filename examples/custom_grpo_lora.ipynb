{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "cb0fa"
   },
   "source": [
    "# Import necessary packages if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "532ee",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install mlx-lm-lora mlx-lm datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "a84b2"
   },
   "source": [
    "# Import your needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "d0596"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mlx_lm_lora.trainer.grpo_trainer import GRPOTrainingArgs, train_grpo\n",
    "from mlx_lm_lora.trainer.datasets import CacheDataset, GRPODataset\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import create_repo, HfApi\n",
    "\n",
    "from mlx_lm.tuner.utils import linear_to_lora_layers, print_trainable_parameters\n",
    "from mlx_lm.tuner.callbacks import TrainingCallback\n",
    "from mlx_lm.utils import load, save_config\n",
    "\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "c9554"
   },
   "source": [
    "# Define the Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "219bf"
   },
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\") # <-- Add you HF Token here\n",
    "\n",
    "model_name = \"mlx-community/Josiefied-Qwen3-0.6B-abliterated-v1-bf16\"\n",
    "new_model_name = \"new_model\"\n",
    "user_name = \"mlx-community\"\n",
    "\n",
    "adapter_path = \"adapters\"\n",
    "new_model_path = \"new_model\"\n",
    "max_seq_length = 1028\n",
    "num_layers = 12\n",
    "lora_parameters = {\"rank\": 8, \"dropout\": 0.0, \"scale\": 10.0}\n",
    "\n",
    "dataset_name = \"Goekdeniz-Guelmez/Big-Math-RL-Verified-MLX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "960f7"
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "0d6f4"
   },
   "outputs": [],
   "source": [
    "model, tokenizer = load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "c15a2"
   },
   "source": [
    "# Convert to LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "2c922"
   },
   "outputs": [],
   "source": [
    "model.freeze()\n",
    "\n",
    "linear_to_lora_layers(\n",
    "    model=model,\n",
    "    num_layers=num_layers,\n",
    "    config=lora_parameters,\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "d68ad"
   },
   "source": [
    "# Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellUniqueIdByVincent": "643c5"
   },
   "outputs": [],
   "source": [
    "opt = optim.AdamW(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9fac5"
   },
   "source": [
    "# Load and Preprocess your Dataset using your custom Prompt Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellUniqueIdByVincent": "75d2a"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by GÃ¶kdeniz GÃ¼lmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\n",
    "Your only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\n",
    "You Respond in the following format:\n",
    "<josie_thinks>\n",
    "...\n",
    "</josie_thinks>\n",
    "<josie_answers>\n",
    "...\n",
    "</josie_answers>\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"<josie_thinks> {reasoning} </josie_thinks> <josie_answers> {answer} </josie_answers>\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<josie_answers>\")[-1]\n",
    "    answer = answer.split(\"</josie_answers>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split]\n",
    "    data = data.map(lambda x: {\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    })\n",
    "    return data\n",
    "\n",
    "dataset = get_gsm8k_questions()\n",
    "\n",
    "\n",
    "# Reward functions\n",
    "def get_completion_content(completion):\n",
    "    try:\n",
    "        if isinstance(completion, str):\n",
    "            return completion\n",
    "        elif isinstance(completion, dict):\n",
    "            return completion.get('content', '')\n",
    "        elif isinstance(completion, list) and len(completion) > 0:\n",
    "            first_item = completion[0]\n",
    "            if isinstance(first_item, dict):\n",
    "                return first_item.get('content', '')\n",
    "            return str(first_item)\n",
    "        return str(completion)\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def get_prompt_content(prompt):\n",
    "    try:\n",
    "        if isinstance(prompt, str):\n",
    "            return prompt\n",
    "        elif isinstance(prompt, dict):\n",
    "            return prompt.get('content', '')\n",
    "        elif isinstance(prompt, list):\n",
    "            last_item = prompt[-1]\n",
    "            if isinstance(last_item, dict):\n",
    "                return last_item.get('content', '')\n",
    "            return str(last_item)\n",
    "        return str(prompt)\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    q = get_prompt_content(prompts[0])\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"^<josie_thinks> .*? </josie_thinks> <josie_answers> .*? </josie_answers>\\n$\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"<josie_thinks>.*?</josie_thinks><josie_answers>.*?</josie_answers>\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<josie_thinks>\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"</josie_thinks>\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"<josie_answers>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"</josie_answers>\")[-1])*0.001\n",
    "    if text.count(\"</josie_answers>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"</josie_answers>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [get_completion_content(completion) for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "8ee1a"
   },
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "7621a"
   },
   "source": [
    "# ðŸ“¦ Make the Dataset for the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellUniqueIdByVincent": "f793d"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.01, seed=42).values()\n",
    "\n",
    "train_set = GRPODataset(train_dataset, tokenizer)\n",
    "valid_set = GRPODataset(train_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "d0736"
   },
   "source": [
    "# Make the Adapter Folder and save the configs for loading later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "47b67"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"lora_parameters\": lora_parameters,\n",
    "    \"num_layers\": num_layers,\n",
    "}\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "adapter_path = current_dir / \"adapters\"\n",
    "new_model_path = current_dir / \"new_model\"\n",
    "\n",
    "adapter_file = adapter_path / \"adapters.safetensors\"\n",
    "# save_config(vars(args), adapter_path / \"adapter_config.json\")\n",
    "save_config(args, adapter_path / \"adapter_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "56877"
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "3714e"
   },
   "outputs": [],
   "source": [
    "# Define custom reward weights if you want to weight them differently\n",
    "# The weights correspond to the 5 default reward functions in order\n",
    "custom_reward_weights = [\n",
    "    2.0,  # r1_accuracy_reward_func - highest weight for correctness\n",
    "    0.5,  # r1_int_reward_func - medium weight for integer answers\n",
    "    1.0,  # r1_strict_format_reward_func - standard weight for strict formatting\n",
    "    0.8,  # r1_soft_format_reward_func - slightly lower weight for soft formatting  \n",
    "    0.3   # r1_count_xml - lower weight for XML tag counting\n",
    "]\n",
    "\n",
    "train_grpo(\n",
    "    model=model,\n",
    "    ref_model=None,  # Use None to use the same model as reference\n",
    "    tokenizer=tokenizer,  # Add the missing tokenizer argument\n",
    "    optimizer=opt,\n",
    "    train_dataset=CacheDataset(train_set),\n",
    "    val_dataset=CacheDataset(valid_set),\n",
    "    args=GRPOTrainingArgs(\n",
    "        batch_size=1,\n",
    "        iters=20, # 1000,\n",
    "        val_batches=1,\n",
    "        steps_per_report=10, #20,\n",
    "        steps_per_eval=5, # 50,\n",
    "        steps_per_save=10, # 50,\n",
    "        adapter_file=adapter_path,\n",
    "        max_seq_length=max_seq_length,\n",
    "        grad_checkpoint=True,\n",
    "        beta=0.9,\n",
    "        group_size=4,\n",
    "        epsilon=1e-4,\n",
    "        epsilon_high=None,\n",
    "        max_completion_length=512,\n",
    "        reward_weights=custom_reward_weights,  # Use this instead of reward_scaling\n",
    "    ),\n",
    "    training_callback=TrainingCallback()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "684ec"
   },
   "source": [
    "# Fuse the model with the trained adapters and save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "acecd",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mlx_lm.fuse --model mlx-community/Josiefied-Qwen3-0.6B-abliterated-v1-4bit --adapter-path adapters --save-path new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "62a64"
   },
   "source": [
    "# Create the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cellUniqueIdByVincent": "7467d"
   },
   "outputs": [],
   "source": [
    "readme_file = f\"\"\"---\n",
    "tags:\n",
    "- mlx\n",
    "- lora\n",
    "- text-generation\n",
    "- fine-tuning\n",
    "base_model: {model_name}\n",
    "pipeline_tag: text-generation\n",
    "---\n",
    "\n",
    "# LoRA Fine-Tuned Model: `{user_name}/{new_model_name}`\n",
    "\n",
    "This model is a LoRA fine-tuned version `{model_name}`, with the [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) training package on Apple Silicon using MLX.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§¾ Model Details\n",
    "\n",
    "- **Model name:** {new_model_name}\n",
    "- **Base model:** {model_name}\n",
    "- **Fine-tuning method:** GRPO\n",
    "- **Training package:** [`MLX-LM-LORA`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora)\n",
    "- **Model type:** {model.args.model_type}\n",
    "- **Author:** None\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Recommended System Prompt\n",
    "\n",
    "```text\n",
    "{system_prompt}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "new_readme_path = f\"{new_model_name}/README.md\"\n",
    "with open(new_readme_path, \"w\") as new_readme_file:\n",
    "    new_readme_file.write(readme_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "fa2d5"
   },
   "source": [
    "# Upload it to HugginFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "49415"
   },
   "outputs": [],
   "source": [
    "api = HfApi(token=hf_token)\n",
    "create_repo(\n",
    "  repo_id = f\"{user_name}/{new_model_name}\",\n",
    "  repo_type=\"model\",\n",
    "  exist_ok=True,\n",
    "  token=hf_token,\n",
    "  private=True\n",
    ")\n",
    "api.upload_folder(\n",
    "  folder_path=new_model_name,\n",
    "  repo_id=f\"{user_name}/{new_model_name}\",\n",
    "  token=hf_token,\n",
    "  commit_message=\"Initial Commit\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "b2033bfa69d74fb50226d93f_2025-05-28T22-11-53-238Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
